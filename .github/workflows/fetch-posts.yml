name: Fetch New Blog Posts

on:
  schedule:
    # Run daily at 11:30 AM UK time
    # GMT period (Oct-Dec): 11:30 AM UTC = 11:30 AM UK time
    - cron: '30 11 * 10-12 *'
    # GMT period (Jan-Mar): 11:30 AM UTC = 11:30 AM UK time
    - cron: '30 11 * 1-3 *'
    # BST period (Apr-Sep): 10:30 AM UTC = 11:30 AM UK time  
    - cron: '30 10 * 4-9 *'
  
  # Allow manual trigger
  workflow_dispatch:

jobs:
  fetch-posts:
    runs-on: ubuntu-latest
    permissions:
      actions: write
      contents: read
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create data directory
      run: mkdir -p data

    - name: Find latest database artifact from any workflow
      id: get_latest_db
      uses: actions/github-script@v7
      with:
        script: |
          // Search for database artifact across all workflows and find the most recent one
          const workflows = ['fetch-posts.yml', 'daily-post.yml', 'database-status.yml'];
          
          console.log('=== SEARCHING FOR MOST RECENT DATABASE ARTIFACT ===');
          
          let newestArtifact = null;
          let newestTime = null;
          
          for (const workflow of workflows) {
            console.log(`\n--- Checking ${workflow} ---`);
            try {
              const runs = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: workflow,
                branch: 'main',
                per_page: 20,
                status: 'success'
              });
              
              console.log(`Found ${runs.data.workflow_runs.length} successful runs`);
              
              // Check each run for the database artifact
              for (const run of runs.data.workflow_runs) {
                try {
                  const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    run_id: run.id,
                  });
                  
                  const dbArtifact = artifacts.data.artifacts.find(a => a.name === 'posts-database');
                  if (dbArtifact) {
                    const artifactTime = new Date(run.created_at);
                    console.log(`  Found database in run ${run.id} (${run.created_at})`);
                    
                    // Keep track of the newest artifact found
                    if (!newestTime || artifactTime > newestTime) {
                      console.log(`    → This is the newest so far!`);
                      newestTime = artifactTime;
                      newestArtifact = {
                        run_id: run.id,
                        workflow_name: workflow,
                        created_at: run.created_at,
                        artifact_id: dbArtifact.id,
                        size: dbArtifact.size_in_bytes
                      };
                    } else {
                      console.log(`    → Older than current newest (${newestArtifact.created_at})`);
                    }
                  }
                } catch (error) {
                  console.log(`Could not check artifacts for run ${run.id}: ${error.message}`);
                }
              }
            } catch (error) {
              console.log(`Error fetching runs for ${workflow}: ${error.message}`);
            }
          }
          
          // Use the newest artifact found
          if (newestArtifact) {
            console.log(`\n✅ USING NEWEST DATABASE:`);
            console.log(`   Workflow: ${newestArtifact.workflow_name}`);
            console.log(`   Run ID: ${newestArtifact.run_id}`);
            console.log(`   Created: ${newestArtifact.created_at}`);
            console.log(`   Artifact ID: ${newestArtifact.artifact_id}`);
            console.log(`   Size: ${newestArtifact.size} bytes`);
            core.setOutput('run_id', String(newestArtifact.run_id));
            core.setOutput('workflow_name', newestArtifact.workflow_name);
            core.setOutput('created_at', newestArtifact.created_at);
            core.setOutput('artifact_id', String(newestArtifact.artifact_id));
          } else {
            console.log('\n❌ No database artifact found in any recent workflow runs');
            core.setOutput('run_id', '');
            core.setOutput('artifact_id', '');
          }

    - name: Download latest database (if any)
      if: steps.get_latest_db.outputs.run_id != ''
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        echo "Downloading latest database from ${{ steps.get_latest_db.outputs.workflow_name }} run ${{ steps.get_latest_db.outputs.run_id }}"
        echo "Created at: ${{ steps.get_latest_db.outputs.created_at }}"
        gh run download ${{ steps.get_latest_db.outputs.run_id }} --name posts-database --dir data/ || echo "No existing database found"
      continue-on-error: true

    - name: Find latest images artifact from any workflow
      id: get_latest_images
      uses: actions/github-script@v7
      with:
        script: |
          // Search for images artifact across all workflows and find the most recent one
          const workflows = ['fetch-posts.yml', 'daily-post.yml', 'database-status.yml'];
          
          console.log('=== SEARCHING FOR MOST RECENT IMAGES ARTIFACT ===');
          
          let newestArtifact = null;
          let newestTime = null;
          
          for (const workflow of workflows) {
            console.log(`\n--- Checking ${workflow} ---`);
            try {
              const runs = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: workflow,
                branch: 'main',
                per_page: 20,
                status: 'success'
              });
              
              // Check each run for the images artifact
              for (const run of runs.data.workflow_runs) {
                try {
                  const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    run_id: run.id,
                  });
                  
                  const imagesArtifact = artifacts.data.artifacts.find(a => a.name === 'images');
                  if (imagesArtifact) {
                    const artifactTime = new Date(run.created_at);
                    console.log(`  Found images in run ${run.id} (${run.created_at})`);
                    
                    // Keep track of the newest artifact found
                    if (!newestTime || artifactTime > newestTime) {
                      console.log(`    → This is the newest so far!`);
                      newestTime = artifactTime;
                      newestArtifact = {
                        run_id: run.id,
                        workflow_name: workflow,
                        created_at: run.created_at,
                        artifact_id: imagesArtifact.id
                      };
                    } else {
                      console.log(`    → Older than current newest (${newestArtifact.created_at})`);
                    }
                  }
                } catch (error) {
                  console.log(`Could not check artifacts for run ${run.id}: ${error.message}`);
                }
              }
            } catch (error) {
              console.log(`Error fetching runs for ${workflow}: ${error.message}`);
            }
          }
          
          // Use the newest artifact found
          if (newestArtifact) {
            console.log(`\n✅ USING NEWEST IMAGES:`);
            console.log(`   Workflow: ${newestArtifact.workflow_name}`);
            console.log(`   Run ID: ${newestArtifact.run_id}`);
            console.log(`   Created: ${newestArtifact.created_at}`);
            core.setOutput('run_id', String(newestArtifact.run_id));
            core.setOutput('workflow_name', newestArtifact.workflow_name);
            core.setOutput('created_at', newestArtifact.created_at);
            core.setOutput('artifact_id', String(newestArtifact.artifact_id));
          } else {
            console.log('\n❌ No images artifact found in any recent workflow runs');
            core.setOutput('run_id', '');
            core.setOutput('artifact_id', '');
          }

    - name: Download latest images artifact
      if: steps.get_latest_images.outputs.run_id != ''
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        echo "Downloading images artifact from ${{ steps.get_latest_images.outputs.workflow_name }} run ${{ steps.get_latest_images.outputs.run_id }}"
        echo "Created at: ${{ steps.get_latest_images.outputs.created_at }}"
        gh run download ${{ steps.get_latest_images.outputs.run_id }} --name images --dir artifacts/images/ || echo "images artifact not found"
      continue-on-error: true

    - name: Prepare artifact directory
      run: |
        mkdir -p artifacts/images
    
    - name: Fetch and process new posts
      env:
        BLOG_RSS_FEED_URL: ${{ secrets.BLOG_RSS_FEED_URL }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        XAI_API_KEY: ${{ secrets.XAI_API_KEY }}
        GENERATE_IMAGES: ${{ vars.GENERATE_IMAGES || '1.0' }}
        MINIMUM_POST_DATE: ${{ secrets.MINIMUM_POST_DATE || '2025-09-24' }}
        MAX_SCHEDULE_DAYS_AHEAD: ${{ vars.MAX_SCHEDULE_DAYS_AHEAD || '7' }}
        DATABASE_PATH: ./data/posts.db
        POSTS_PER_BLOG: ${{ vars.POSTS_PER_BLOG || 5 }}
        MAX_BLOG_POSTS_PER_RUN: ${{ vars.MAX_BLOG_POSTS_PER_RUN || 0 }}
        IMAGE_OUTPUT_DIR: ./artifacts/images
        PYTHONUNBUFFERED: 1
      run: |
        python -u main.py --fetch-posts
    
    - name: Regenerate missing images for unposted messages
      env:
        BLOG_RSS_FEED_URL: ${{ secrets.BLOG_RSS_FEED_URL }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        XAI_API_KEY: ${{ secrets.XAI_API_KEY }}
        GENERATE_IMAGES: ${{ vars.GENERATE_IMAGES || '1.0' }}
        DATABASE_PATH: ./data/posts.db
        IMAGE_OUTPUT_DIR: ./artifacts/images
        PYTHONUNBUFFERED: 1
      run: |
        python -u main.py --regenerate-missing-images
    
    - name: Check and regenerate short unposted messages
      # This step finds messages shorter than 280 characters that haven't been posted yet
      # and regenerates them with longer, more detailed content using Anthropic, then updates the database
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        DATABASE_PATH: ./data/posts.db
        X_PREMIUM_ACCOUNT: ${{ vars.X_PREMIUM_ACCOUNT || 'true' }}
        PYTHONUNBUFFERED: 1
      run: |
        echo "🔍 Checking for short unposted messages..."
        echo "This step will find messages shorter than 280 characters that haven't been posted yet"
        echo "and regenerate them with longer, more detailed content, then update the database."
        echo ""
        python -u regenerate_short_messages.py
        echo ""
        echo "📊 Short message regeneration and database update complete!"
    
    - name: Upload generated images artifact
      if: ${{ hashFiles('artifacts/images/**') != '' }}
      uses: actions/upload-artifact@v4
      with:
        name: images
        path: artifacts/images
        if-no-files-found: ignore
    
    - name: Upload database as artifact
      uses: actions/upload-artifact@v4
      with:
        name: posts-database
        path: data/posts.db
        retention-days: 90
    
    - name: Show status
      env:
        BLOG_RSS_FEED_URL: ${{ secrets.BLOG_RSS_FEED_URL }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        MINIMUM_POST_DATE: ${{ secrets.MINIMUM_POST_DATE || '2025-09-24' }}
        DATABASE_PATH: ./data/posts.db
      run: |
        python main.py --status