name: Daily Social Media Post

on:
  schedule:
    # Reliable posting schedule with buffer time for GitHub cron variance
    # Target: 9:00 AM ET posting with 15-minute buffer
    # 8:45 AM EST = 13:45 UTC (EST) / 12:45 UTC (EDT)
    # 10:45 AM EST = 15:45 UTC (EST) / 14:45 UTC (EDT)  
    # 12:45 PM EST = 17:45 UTC (EST) / 16:45 UTC (EDT)
    # 2:45 PM EST = 19:45 UTC (EST) / 18:45 UTC (EDT)
    
    # Winter schedule (EST - Nov-Mar) - 15 min buffer before target time
    - cron: '45 13 * 11-12,1-3 1-5'  # 8:45am EST, Mon-Fri
    - cron: '45 15 * 11-12,1-3 1-5'  # 10:45am EST, Mon-Fri
    - cron: '45 17 * 11-12,1-3 1-5'  # 12:45pm EST, Mon-Fri
    - cron: '45 19 * 11-12,1-3 1-5'  # 2:45pm EST, Mon-Fri
    
    # Summer schedule (EDT - Mar-Nov) - 15 min buffer before target time
    - cron: '45 12 * 4-10 1-5'  # 8:45am EDT, Mon-Fri
    - cron: '45 14 * 4-10 1-5'  # 10:45am EDT, Mon-Fri
    - cron: '45 16 * 4-10 1-5'  # 12:45pm EDT, Mon-Fri
    - cron: '45 18 * 4-10 1-5'  # 2:45pm EDT, Mon-Fri
  
  # Allow manual trigger
  workflow_dispatch:

jobs:
  post-daily:
    runs-on: ubuntu-latest
    permissions:
      actions: write
      contents: read
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create data directory
      run: mkdir -p data
    
    - name: Find latest database from any workflow
      id: get_latest_db
      uses: actions/github-script@v7
      with:
        script: |
          // Get runs from all three workflows
          const workflows = ['fetch-posts.yml', 'daily-post.yml', 'clear-unposted.yml'];
          const allRuns = [];
          
          for (const workflow of workflows) {
            try {
              const runs = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: workflow,
                branch: 'main',
                per_page: 10,
                status: 'success'
              });
              if (runs.data.workflow_runs) {
                allRuns.push(...runs.data.workflow_runs.map(run => ({
                  ...run,
                  workflow_name: workflow
                })));
              }
            } catch (error) {
              console.log(`Error fetching runs for ${workflow}:`, error.message);
            }
          }
          
          // Sort by creation time (newest first)
          allRuns.sort((a, b) => new Date(b.created_at) - new Date(a.created_at));
          
          const latestRun = allRuns[0];
          if (latestRun) {
            console.log(`Latest database source: ${latestRun.workflow_name} (run ${latestRun.id})`);
            core.setOutput('run_id', String(latestRun.id));
            core.setOutput('workflow_name', latestRun.workflow_name);
            core.setOutput('created_at', latestRun.created_at);
          } else {
            console.log('No successful workflow runs found');
            core.setOutput('run_id', '');
          }

    - name: Download latest database
      if: steps.get_latest_db.outputs.run_id != ''
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        echo "Downloading latest database from ${{ steps.get_latest_db.outputs.workflow_name }} run ${{ steps.get_latest_db.outputs.run_id }}"
        echo "Created at: ${{ steps.get_latest_db.outputs.created_at }}"
        gh run download ${{ steps.get_latest_db.outputs.run_id }} --name posts-database --dir data/ || echo "posts-database not found"
      continue-on-error: true

    - name: Download images artifact from latest run
      if: steps.get_latest_db.outputs.run_id != ''
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        echo "Downloading images artifact from ${{ steps.get_latest_db.outputs.workflow_name }} run ${{ steps.get_latest_db.outputs.run_id }}"
        gh run download ${{ steps.get_latest_db.outputs.run_id }} --name images --dir artifacts/images/ || echo "images artifact not found"
      continue-on-error: true
    
    - name: Post daily message
      env:
        BLOG_RSS_FEED_URL: ${{ secrets.BLOG_RSS_FEED_URL }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        XAI_API_KEY: ${{ secrets.XAI_API_KEY }}
        GENERATE_IMAGES: ${{ vars.GENERATE_IMAGES || '1.0' }}
        LINKEDIN_ENABLED: ${{ secrets.LINKEDIN_ENABLED || 'false' }}
        LINKEDIN_ACCESS_TOKEN: ${{ secrets.LINKEDIN_ACCESS_TOKEN }}
        LINKEDIN_USER_ID: ${{ secrets.LINKEDIN_USER_ID }}
        LINKEDIN_ORG_ID: ${{ secrets.LINKEDIN_ORG_ID }}
        LINKEDIN_POST_AS_ORG: ${{ secrets.LINKEDIN_POST_AS_ORG }}
        X_API_KEY: ${{ secrets.X_API_KEY }}
        X_API_SECRET: ${{ secrets.X_API_SECRET }}
        X_ACCESS_TOKEN: ${{ secrets.X_ACCESS_TOKEN }}
        X_ACCESS_TOKEN_SECRET: ${{ secrets.X_ACCESS_TOKEN_SECRET }}
        X_BEARER_TOKEN: ${{ secrets.X_BEARER_TOKEN }}
        DATABASE_PATH: ./data/posts.db
        POSTS_PER_BLOG: ${{ vars.POSTS_PER_BLOG || 5 }}
        IMAGE_OUTPUT_DIR: ./artifacts/images
        TEST_MODE: ${{ vars.TEST_MODE || 'false' }}
      run: |
        python main.py --post-daily
    
    - name: Cleanup artifacts folder (post-run)
      if: always()
      run: |
        rm -rf artifacts/images || true
    
    - name: Upload database as artifact
      uses: actions/upload-artifact@v4
      with:
        name: posts-database
        path: data/posts.db
        retention-days: 90