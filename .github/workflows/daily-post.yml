name: Daily Social Media Post

on:
  schedule:
    # Post at exact times with time slot window logic
    # 9:00 AM EST = 14:00 UTC (EST) / 13:00 UTC (EDT)
    # 11:00 AM EST = 16:00 UTC (EST) / 15:00 UTC (EDT)  
    # 1:00 PM EST = 18:00 UTC (EST) / 17:00 UTC (EDT)
    # 3:00 PM EST = 20:00 UTC (EST) / 19:00 UTC (EDT)
    
    # Winter schedule (EST - Nov-Mar)
    - cron: '0 14 * 11-12,1-3 1-5'  # 9am EST, Mon-Fri
    - cron: '0 16 * 11-12,1-3 1-5'  # 11am EST, Mon-Fri
    - cron: '0 18 * 11-12,1-3 1-5'  # 1pm EST, Mon-Fri
    - cron: '0 20 * 11-12,1-3 1-5'  # 3pm EST, Mon-Fri
    
    # Summer schedule (EDT - Mar-Nov)  
    - cron: '0 13 * 4-10 1-5'  # 9am EDT, Mon-Fri
    - cron: '0 15 * 4-10 1-5'  # 11am EDT, Mon-Fri
    - cron: '0 17 * 4-10 1-5'  # 1pm EDT, Mon-Fri
    - cron: '0 19 * 4-10 1-5'  # 3pm EDT, Mon-Fri
  
  # Allow manual trigger
  workflow_dispatch:

jobs:
  post-daily:
    runs-on: ubuntu-latest
    permissions:
      actions: write
      contents: read
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create data directory
      run: mkdir -p data
    
    - name: Find latest database artifact from any workflow
      id: get_latest_db
      uses: actions/github-script@v7
      with:
        script: |
          // Search for database artifact across all workflows
          const workflows = ['fetch-posts.yml', 'daily-post.yml', 'database-status.yml'];
          
          for (const workflow of workflows) {
            try {
              const runs = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: workflow,
                branch: 'main',
                per_page: 20,
                status: 'success'
              });
              
              // Check each run for the database artifact
              for (const run of runs.data.workflow_runs) {
                try {
                  const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    run_id: run.id,
                  });
                  
                  const dbArtifact = artifacts.data.artifacts.find(a => a.name === 'posts-database');
                  if (dbArtifact) {
                    console.log(`✅ Found database in ${workflow} run ${run.id} (created: ${run.created_at})`);
                    core.setOutput('run_id', String(run.id));
                    core.setOutput('workflow_name', workflow);
                    core.setOutput('created_at', run.created_at);
                    core.setOutput('artifact_id', String(dbArtifact.id));
                    return;
                  }
                } catch (error) {
                  console.log(`Could not check artifacts for run ${run.id}: ${error.message}`);
                }
              }
            } catch (error) {
              console.log(`Error fetching runs for ${workflow}: ${error.message}`);
            }
          }
          
          console.log('❌ No database artifact found in any recent workflow runs');
          core.setOutput('run_id', '');
          core.setOutput('artifact_id', '');

    - name: Download latest database
      if: steps.get_latest_db.outputs.run_id != ''
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        echo "Downloading latest database from ${{ steps.get_latest_db.outputs.workflow_name }} run ${{ steps.get_latest_db.outputs.run_id }}"
        echo "Created at: ${{ steps.get_latest_db.outputs.created_at }}"
        echo "Artifact ID: ${{ steps.get_latest_db.outputs.artifact_id }}"
        gh run download ${{ steps.get_latest_db.outputs.run_id }} --name posts-database --dir data/ || echo "posts-database not found"
        
        # Verify database was downloaded
        if [ -f "data/posts.db" ]; then
          echo "✅ Database downloaded successfully"
          echo "Database size: $(du -h data/posts.db | cut -f1)"
          echo "Database last modified: $(stat -f '%Sm' -t '%Y-%m-%d %H:%M:%S' data/posts.db 2>/dev/null || stat -c '%y' data/posts.db 2>/dev/null)"
          
          # Show database stats
          echo "Database contents:"
          sqlite3 data/posts.db "SELECT COUNT(*) as total_posts FROM blog_posts;" 2>/dev/null || echo "Could not read blog_posts"
          sqlite3 data/posts.db "SELECT COUNT(*) as total_messages FROM posted_messages;" 2>/dev/null || echo "Could not read posted_messages"
          sqlite3 data/posts.db "SELECT COUNT(*) as fully_posted FROM posted_messages WHERE posted_to_linkedin = 1 AND posted_to_x = 1;" 2>/dev/null || echo "Could not read posted status"
        else
          echo "❌ Database file not found after download"
        fi
      continue-on-error: true

    - name: Find latest images artifact from any workflow
      id: get_latest_images
      uses: actions/github-script@v7
      with:
        script: |
          // Search for images artifact across all workflows
          const workflows = ['fetch-posts.yml', 'daily-post.yml', 'database-status.yml'];
          
          for (const workflow of workflows) {
            try {
              const runs = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: workflow,
                branch: 'main',
                per_page: 20,
                status: 'success'
              });
              
              // Check each run for the images artifact
              for (const run of runs.data.workflow_runs) {
                try {
                  const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    run_id: run.id,
                  });
                  
                  const imagesArtifact = artifacts.data.artifacts.find(a => a.name === 'images');
                  if (imagesArtifact) {
                    console.log(`✅ Found images in ${workflow} run ${run.id} (created: ${run.created_at})`);
                    core.setOutput('run_id', String(run.id));
                    core.setOutput('workflow_name', workflow);
                    core.setOutput('created_at', run.created_at);
                    core.setOutput('artifact_id', String(imagesArtifact.id));
                    return;
                  }
                } catch (error) {
                  console.log(`Could not check artifacts for run ${run.id}: ${error.message}`);
                }
              }
            } catch (error) {
              console.log(`Error fetching runs for ${workflow}: ${error.message}`);
            }
          }
          
          console.log('❌ No images artifact found in any recent workflow runs');
          core.setOutput('run_id', '');
          core.setOutput('artifact_id', '');

    - name: Download latest images artifact
      if: steps.get_latest_images.outputs.run_id != ''
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        echo "Downloading images artifact from ${{ steps.get_latest_images.outputs.workflow_name }} run ${{ steps.get_latest_images.outputs.run_id }}"
        echo "Created at: ${{ steps.get_latest_images.outputs.created_at }}"
        gh run download ${{ steps.get_latest_images.outputs.run_id }} --name images --dir artifacts/images/ || echo "images artifact not found"
      continue-on-error: true
    
    - name: Prepare artifact directory
      run: |
        mkdir -p artifacts/images
    
    - name: Check image artifacts and validate database entries
      env:
        DATABASE_PATH: ./data/posts.db
        IMAGE_OUTPUT_DIR: ./artifacts/images
        PYTHONUNBUFFERED: 1
      run: |
        echo "=== IMAGE ARTIFACT DIAGNOSTICS ==="
        echo "Checking artifacts/images directory..."
        ls -la artifacts/images/ || echo "No artifacts/images directory found"
        echo ""
        echo "All files in artifacts directory:"
        find artifacts -type f 2>/dev/null || echo "No artifacts directory found"
        echo ""
        echo "Checking for image files..."
        find artifacts/images -name "*.jpg" -o -name "*.png" -o -name "*.jpeg" 2>/dev/null || echo "No image files found"
        echo ""
        echo "=== DATABASE IMAGE VALIDATION ==="
        python3 -c "
        import sqlite3
        import os
        
        if os.path.exists('./data/posts.db'):
            conn = sqlite3.connect('./data/posts.db')
            cursor = conn.cursor()
            
            # Get all messages with image URLs (join with blog_posts to get title)
            cursor.execute('''
                SELECT pm.id, pm.image_url, bp.title, pm.message_text
                FROM posted_messages pm
                JOIN blog_posts bp ON pm.blog_post_id = bp.id
                WHERE pm.image_url IS NOT NULL
                ORDER BY pm.id DESC
                LIMIT 10
            ''')
            
            messages = cursor.fetchall()
            print(f'Found {len(messages)} messages with image URLs in database')
            
            for msg in messages:
                msg_id, image_url, blog_title, message_text = msg
                print(f'\\nMessage ID: {msg_id}')
                print(f'Blog: {blog_title[:50]}...')
                print(f'Image URL: {image_url}')
                
                if os.path.isfile(image_url):
                    print('✅ Image file exists')
                else:
                    print('❌ Image file missing')
                    # Check if it's in the artifacts directory
                    if image_url.startswith('./artifacts/images/'):
                        filename = os.path.basename(image_url)
                        artifacts_path = f'./artifacts/images/{filename}'
                        if os.path.isfile(artifacts_path):
                            print(f'✅ Found in artifacts: {artifacts_path}')
                        else:
                            print(f'❌ Not found in artifacts: {artifacts_path}')
                    else:
                        print(f'❌ Path not in artifacts directory: {image_url}')
            
            conn.close()
        else:
            print('No database file found')
        "
        echo ""
        echo "=== END DIAGNOSTICS ==="
    
    - name: Post daily message
      env:
        BLOG_RSS_FEED_URL: ${{ secrets.BLOG_RSS_FEED_URL }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        XAI_API_KEY: ${{ secrets.XAI_API_KEY }}
        GENERATE_IMAGES: ${{ vars.GENERATE_IMAGES || '1.0' }}
        LINKEDIN_ENABLED: ${{ secrets.LINKEDIN_ENABLED || 'false' }}
        LINKEDIN_ACCESS_TOKEN: ${{ secrets.LINKEDIN_ACCESS_TOKEN }}
        LINKEDIN_USER_ID: ${{ secrets.LINKEDIN_USER_ID }}
        LINKEDIN_ORG_ID: ${{ secrets.LINKEDIN_ORG_ID }}
        LINKEDIN_POST_AS_ORG: ${{ secrets.LINKEDIN_POST_AS_ORG }}
        X_API_KEY: ${{ secrets.X_API_KEY }}
        X_API_SECRET: ${{ secrets.X_API_SECRET }}
        X_ACCESS_TOKEN: ${{ secrets.X_ACCESS_TOKEN }}
        X_ACCESS_TOKEN_SECRET: ${{ secrets.X_ACCESS_TOKEN_SECRET }}
        X_BEARER_TOKEN: ${{ secrets.X_BEARER_TOKEN }}
        DATABASE_PATH: ./data/posts.db
        POSTS_PER_BLOG: ${{ vars.POSTS_PER_BLOG || 5 }}
        IMAGE_OUTPUT_DIR: ./artifacts/images
        TEST_MODE: ${{ vars.TEST_MODE || 'false' }}
      run: |
        python main.py --post-daily
    
    - name: Cleanup used image file (post-run)
      if: success()
      run: |
        # Only delete the specific image file that was used for posting
        # The main.py script handles individual image cleanup after successful posting
        echo "Image cleanup is handled by main.py after successful posting"
    
    - name: Upload images artifact (if any exist)
      if: ${{ hashFiles('artifacts/images/**') != '' }}
      uses: actions/upload-artifact@v4
      with:
        name: images
        path: artifacts/images
        retention-days: 90
        if-no-files-found: ignore
    
    - name: Pre-upload database verification
      run: |
        echo "=== PRE-UPLOAD DATABASE VERIFICATION ==="
        if [ -f "data/posts.db" ]; then
          echo "✅ Database file exists"
          echo "Database size: $(du -h data/posts.db | cut -f1)"
          echo "Database last modified: $(stat -f '%Sm' -t '%Y-%m-%d %H:%M:%S' data/posts.db 2>/dev/null || stat -c '%y' data/posts.db 2>/dev/null)"
          echo ""
          echo "Database posting status:"
          sqlite3 data/posts.db "
            SELECT 
              COUNT(*) as total,
              SUM(CASE WHEN posted_to_linkedin = 1 AND posted_to_x = 1 THEN 1 ELSE 0 END) as fully_posted,
              SUM(CASE WHEN posted_to_linkedin = 0 AND posted_to_x = 0 THEN 1 ELSE 0 END) as unposted
            FROM posted_messages;
          " 2>/dev/null || echo "Could not query database"
        else
          echo "❌ Database file does not exist - nothing to upload!"
        fi
        echo "=== END PRE-UPLOAD VERIFICATION ==="
    
    - name: Upload database as artifact
      uses: actions/upload-artifact@v4
      with:
        name: posts-database
        path: data/posts.db
        retention-days: 90