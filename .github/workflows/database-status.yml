# yamllint disable-line rule:truthy
name: Database Status Check

on:
  # Allow manual trigger
  workflow_dispatch:
  
  # Allow triggering from other workflows
  repository_dispatch:
    types: [database-status]

jobs:
  database-status:
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create data directory
      run: mkdir -p data

    - name: Remove any stale local database
      run: |
        rm -f data/posts.db || true

    - name: Find latest database artifact from any workflow
      id: get_latest_db
      uses: actions/github-script@v7
      with:
        script: |
          // Search for database artifact across all workflows and find the most recent one
          const workflows = ['fetch-posts.yml', 'daily-post.yml', 'database-status.yml'];
          
          console.log('=== SEARCHING FOR MOST RECENT DATABASE ARTIFACT ===');
          
          let newestArtifact = null;
          let newestTime = null;
          
          for (const workflow of workflows) {
            console.log(`\n--- Checking ${workflow} ---`);
            try {
              const runs = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: workflow,
                branch: 'main',
                per_page: 20,
                status: 'success'
              });
              
              console.log(`Found ${runs.data.workflow_runs.length} successful runs`);
              
              // Check each run for the database artifact
              for (const run of runs.data.workflow_runs) {
                try {
                  const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    run_id: run.id,
                  });
                  
                  const dbArtifact = artifacts.data.artifacts.find(a => a.name === 'posts-database');
                  if (dbArtifact) {
                    const artifactTime = new Date(run.created_at);
                    console.log(`  Found database in run ${run.id} (${run.created_at})`);
                    
                    // Keep track of the newest artifact found
                    if (!newestTime || artifactTime > newestTime) {
                      console.log(`    → This is the newest so far!`);
                      newestTime = artifactTime;
                      newestArtifact = {
                        run_id: run.id,
                        workflow_name: workflow,
                        created_at: run.created_at,
                        artifact_id: dbArtifact.id,
                        size: dbArtifact.size_in_bytes
                      };
                    } else {
                      console.log(`    → Older than current newest (${newestArtifact.created_at})`);
                    }
                  }
                } catch (error) {
                  console.log(`Could not check artifacts for run ${run.id}: ${error.message}`);
                }
              }
            } catch (error) {
              console.log(`Error fetching runs for ${workflow}: ${error.message}`);
            }
          }
          
          // Use the newest artifact found
          if (newestArtifact) {
            console.log(`\n✅ USING NEWEST DATABASE:`);
            console.log(`   Workflow: ${newestArtifact.workflow_name}`);
            console.log(`   Run ID: ${newestArtifact.run_id}`);
            console.log(`   Created: ${newestArtifact.created_at}`);
            console.log(`   Artifact ID: ${newestArtifact.artifact_id}`);
            console.log(`   Size: ${newestArtifact.size} bytes`);
            core.setOutput('run_id', String(newestArtifact.run_id));
            core.setOutput('workflow_name', newestArtifact.workflow_name);
            core.setOutput('created_at', newestArtifact.created_at);
            core.setOutput('artifact_id', String(newestArtifact.artifact_id));
          } else {
            console.log('\n❌ No database artifact found in any recent workflow runs');
            core.setOutput('run_id', '');
            core.setOutput('artifact_id', '');
          }

    - name: Download latest database
      if: steps.get_latest_db.outputs.run_id != ''
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        echo "Downloading database from ${{ steps.get_latest_db.outputs.workflow_name }} run ${{ steps.get_latest_db.outputs.run_id }}"
        echo "Created at: ${{ steps.get_latest_db.outputs.created_at }}"
        gh run download ${{ steps.get_latest_db.outputs.run_id }} --name posts-database --dir data/ || echo "posts-database not found"
      continue-on-error: true

    - name: Find latest images artifact from any workflow
      id: get_latest_images
      uses: actions/github-script@v7
      with:
        script: |
          // Search for images artifact across all workflows and find the most recent one
          const workflows = ['fetch-posts.yml', 'daily-post.yml', 'database-status.yml'];
          
          console.log('=== SEARCHING FOR MOST RECENT IMAGES ARTIFACT ===');
          
          let newestArtifact = null;
          let newestTime = null;
          
          for (const workflow of workflows) {
            console.log(`\n--- Checking ${workflow} ---`);
            try {
              const runs = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: workflow,
                branch: 'main',
                per_page: 20,
                status: 'success'
              });
              
              // Check each run for the images artifact
              for (const run of runs.data.workflow_runs) {
                try {
                  const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    run_id: run.id,
                  });
                  
                  const imagesArtifact = artifacts.data.artifacts.find(a => a.name === 'images');
                  if (imagesArtifact) {
                    const artifactTime = new Date(run.created_at);
                    console.log(`  Found images in run ${run.id} (${run.created_at})`);
                    
                    // Keep track of the newest artifact found
                    if (!newestTime || artifactTime > newestTime) {
                      console.log(`    → This is the newest so far!`);
                      newestTime = artifactTime;
                      newestArtifact = {
                        run_id: run.id,
                        workflow_name: workflow,
                        created_at: run.created_at,
                        artifact_id: imagesArtifact.id
                      };
                    } else {
                      console.log(`    → Older than current newest (${newestArtifact.created_at})`);
                    }
                  }
                } catch (error) {
                  console.log(`Could not check artifacts for run ${run.id}: ${error.message}`);
                }
              }
            } catch (error) {
              console.log(`Error fetching runs for ${workflow}: ${error.message}`);
            }
          }
          
          // Use the newest artifact found
          if (newestArtifact) {
            console.log(`\n✅ USING NEWEST IMAGES:`);
            console.log(`   Workflow: ${newestArtifact.workflow_name}`);
            console.log(`   Run ID: ${newestArtifact.run_id}`);
            console.log(`   Created: ${newestArtifact.created_at}`);
            core.setOutput('run_id', String(newestArtifact.run_id));
            core.setOutput('workflow_name', newestArtifact.workflow_name);
            core.setOutput('created_at', newestArtifact.created_at);
            core.setOutput('artifact_id', String(newestArtifact.artifact_id));
          } else {
            console.log('\n❌ No images artifact found in any recent workflow runs');
            core.setOutput('run_id', '');
            core.setOutput('artifact_id', '');
          }

    - name: Download latest images artifact
      if: steps.get_latest_images.outputs.run_id != ''
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        echo "Downloading images from ${{ steps.get_latest_images.outputs.workflow_name }} run ${{ steps.get_latest_images.outputs.run_id }}"
        echo "Created at: ${{ steps.get_latest_images.outputs.created_at }}"
        gh run download ${{ steps.get_latest_images.outputs.run_id }} --name images --dir artifacts/images/ || echo "images artifact not found"
      continue-on-error: true

    - name: Show database status
      env:
        BLOG_RSS_FEED_URL: ${{ secrets.BLOG_RSS_FEED_URL }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        DATABASE_PATH: ./data/posts.db
        LINKEDIN_ACCESS_TOKEN: ${{ secrets.LINKEDIN_ACCESS_TOKEN }}
        LINKEDIN_USER_ID: ${{ secrets.LINKEDIN_USER_ID }}
        LINKEDIN_ORG_ID: ${{ secrets.LINKEDIN_ORG_ID }}
        LINKEDIN_POST_AS_ORG: ${{ secrets.LINKEDIN_POST_AS_ORG }}
        LINKEDIN_ENABLED: ${{ secrets.LINKEDIN_ENABLED }}
        X_API_KEY: ${{ secrets.X_API_KEY }}
        X_API_SECRET: ${{ secrets.X_API_SECRET }}
        X_ACCESS_TOKEN: ${{ secrets.X_ACCESS_TOKEN }}
        X_ACCESS_TOKEN_SECRET: ${{ secrets.X_ACCESS_TOKEN_SECRET }}
        X_BEARER_TOKEN: ${{ secrets.X_BEARER_TOKEN }}
      run: |
        echo "============================================================"
        echo "DATABASE STATUS REPORT"
        echo "============================================================"
        echo "Timestamp: $(date)"
        echo ""
        
        # Check if database exists
        if [ -f "./data/posts.db" ]; then
          echo "✅ Database file exists: ./data/posts.db"
          echo "📊 Database size: $(du -h ./data/posts.db | cut -f1)"
          echo ""
          
          # Show database contents using Python
          python main.py --status
          echo ""
          
          # Show raw database contents
          echo "📋 Raw Database Contents:"
          echo "------------------------"
          echo "Blog Posts:"
          sqlite3 ./data/posts.db "SELECT id, title, published_date, fetched_at FROM blog_posts ORDER BY published_date DESC LIMIT 10;" || echo "No blog posts found"
          echo ""
          echo "Posted Messages:"
          sqlite3 ./data/posts.db "SELECT id, blog_post_id, message_index, posted_to_linkedin, posted_to_x, posted_at FROM posted_messages ORDER BY id DESC LIMIT 10;" || echo "No posted messages found"
          echo ""
          
          # Show unpublished messages with details
          echo "📝 UNPUBLISHED MESSAGES (Not Posted Yet):"
          echo "=========================================="
          sqlite3 ./data/posts.db "
            SELECT 
              pm.id as msg_id,
              bp.title as blog_title,
              pm.message_index + 1 as msg_num,
              datetime(pm.scheduled_for) as scheduled,
              CASE 
                WHEN pm.posted_to_linkedin = 1 AND pm.posted_to_x = 1 THEN '✅ Both'
                WHEN pm.posted_to_linkedin = 1 THEN '🔗 LinkedIn Only'
                WHEN pm.posted_to_x = 1 THEN '𝕏 X Only'
                ELSE '⏳ Pending'
              END as status,
              pm.message_text as preview
            FROM posted_messages pm
            JOIN blog_posts bp ON pm.blog_post_id = bp.id
            WHERE pm.posted_at IS NULL OR (pm.posted_to_linkedin = 0 OR pm.posted_to_x = 0)
            ORDER BY pm.scheduled_for ASC
          " -header -column || echo "No unpublished messages found"
          echo ""
          echo "Total unpublished messages:"
          sqlite3 ./data/posts.db "
            SELECT COUNT(*) 
            FROM posted_messages 
            WHERE posted_at IS NULL OR (posted_to_linkedin = 0 OR posted_to_x = 0)
          " || echo "0"
          echo ""
          
          # Check image file validity
          echo "🖼️  IMAGE FILE VALIDATION:"
          echo "=========================="
          sqlite3 ./data/posts.db "
            SELECT 
              pm.id as msg_id,
              bp.title as blog_title,
              pm.message_index + 1 as msg_num,
              pm.image_url,
              CASE 
                WHEN pm.image_url IS NULL THEN '❌ No Image'
                WHEN pm.image_url = '' THEN '❌ Empty Path'
                ELSE '📁 ' || pm.image_url
              END as image_status
            FROM posted_messages pm
            JOIN blog_posts bp ON pm.blog_post_id = bp.id
            WHERE pm.posted_to_linkedin = 0 AND pm.posted_to_x = 0
            ORDER BY pm.scheduled_for ASC
          " -header -column || echo "No unposted messages found"
          echo ""
          
          # Check if image files actually exist
          echo "📂 IMAGE FILE EXISTENCE CHECK:"
          echo "=============================="
          sqlite3 ./data/posts.db "
            SELECT 
              pm.id as msg_id,
              bp.title as blog_title,
              pm.message_index + 1 as msg_num,
              pm.image_url,
              CASE 
                WHEN pm.image_url IS NULL THEN '❌ No Image Path'
                WHEN pm.image_url = '' THEN '❌ Empty Path'
                ELSE '🔍 ' || pm.image_url
              END as file_path
            FROM posted_messages pm
            JOIN blog_posts bp ON pm.blog_post_id = bp.id
            WHERE pm.posted_to_linkedin = 0 AND pm.posted_to_x = 0
            ORDER BY pm.scheduled_for ASC
          " -header -column || echo "No unposted messages found"
          echo ""
          
          # Actually check if files exist
          echo "🔍 FILE EXISTENCE VERIFICATION:"
          echo "==============================="
          sqlite3 ./data/posts.db "
            SELECT 
              pm.id as msg_id,
              bp.title as blog_title,
              pm.message_index + 1 as msg_num,
              pm.image_url,
              CASE 
                WHEN pm.image_url IS NULL THEN '❌ No Path'
                WHEN pm.image_url = '' THEN '❌ Empty Path'
                ELSE '📁 ' || pm.image_url
              END as file_path
            FROM posted_messages pm
            JOIN blog_posts bp ON pm.blog_post_id = bp.id
            WHERE pm.posted_to_linkedin = 0 AND pm.posted_to_x = 0
            AND pm.image_url IS NOT NULL AND pm.image_url != ''
            ORDER BY pm.scheduled_for ASC
          " | while IFS='|' read -r msg_id blog_title msg_num image_url file_path; do
            if [[ "$msg_id" != "msg_id" && "$msg_id" != "" ]]; then
              if [[ -f "$image_url" ]]; then
                echo "✅ $msg_id | $blog_title | $msg_num | $image_url | FILE EXISTS"
              else
                echo "❌ $msg_id | $blog_title | $msg_num | $image_url | FILE MISSING"
              fi
            fi
          done
          echo ""
          
          # Count invalid images
          echo "📊 IMAGE VALIDATION SUMMARY:"
          echo "============================"
          echo "Messages with no image path:"
          sqlite3 ./data/posts.db "
            SELECT COUNT(*) 
            FROM posted_messages 
            WHERE posted_to_linkedin = 0 AND posted_to_x = 0 
            AND (image_url IS NULL OR image_url = '')
          " || echo "0"
          echo ""
          echo "Messages with image paths:"
          sqlite3 ./data/posts.db "
            SELECT COUNT(*) 
            FROM posted_messages 
            WHERE posted_to_linkedin = 0 AND posted_to_x = 0 
            AND image_url IS NOT NULL AND image_url != ''
          " || echo "0"
          echo ""
          
          # Simple file existence summary
          echo "📁 FILE EXISTENCE SUMMARY:"
          echo "=========================="
          echo "Note: Detailed file checking is shown above in 'FILE EXISTENCE VERIFICATION' section"
          echo "Total unposted messages with image paths:"
          sqlite3 ./data/posts.db "
            SELECT COUNT(*)
            FROM posted_messages pm
            WHERE pm.posted_to_linkedin = 0 AND pm.posted_to_x = 0
            AND pm.image_url IS NOT NULL AND pm.image_url != ''
          " || echo "0"
          echo ""
          
          echo "Database Schema:"
          sqlite3 ./data/posts.db ".schema"
        else
          echo "❌ Database file does not exist"
          echo "This could mean:"
          echo "  - No workflows have run yet"
          echo "  - No artifacts have been created"
          echo "  - Database hasn't been initialized"
        fi
        
        echo ""
        echo "============================================================"
        echo "END OF DATABASE STATUS REPORT"
        echo "============================================================"
    
    - name: Prepare artifacts directory
      run: |
        mkdir -p artifacts/images
    
    - name: Upload images artifact (if any exist)
      if: ${{ hashFiles('artifacts/images/**') != '' }}
      uses: actions/upload-artifact@v4
      with:
        name: images
        path: artifacts/images
        retention-days: 90
        if-no-files-found: ignore
    
    - name: Upload database as artifact
      if: ${{ hashFiles('data/posts.db') != '' }}
      uses: actions/upload-artifact@v4
      with:
        name: posts-database
        path: data/posts.db
        retention-days: 90
    
    - name: Upload database status report
      if: always() && hashFiles('data/posts.db') != ''
      uses: actions/upload-artifact@v4
      with:
        name: database-status-report
        path: data/posts.db
        retention-days: 7
