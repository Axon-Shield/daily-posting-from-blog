name: Database Status Check

on:
  # Allow manual trigger
  workflow_dispatch:
  
  # Allow triggering from other workflows
  repository_dispatch:
    types: [database-status]

jobs:
  database-status:
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create data directory
      run: mkdir -p data

    - name: Remove any stale local database
      run: |
        rm -f data/posts.db || true

    - name: Get latest successful run id (fetch-posts)
      id: get_run_fetch
      uses: actions/github-script@v7
      with:
        script: |
          const runs = await github.rest.actions.listWorkflowRuns({
            owner: context.repo.owner,
            repo: context.repo.repo,
            workflow_id: 'fetch-posts.yml',
            branch: 'main',
            per_page: 20,
            status: 'success'
          });
          const run = runs.data.workflow_runs && runs.data.workflow_runs[0];
          core.setOutput('run_id', run ? String(run.id) : '');

    - name: List artifacts for fetch-posts run
      if: steps.get_run_fetch.outputs.run_id != ''
      uses: actions/github-script@v7
      with:
        script: |
          const run_id = parseInt('${{ steps.get_run_fetch.outputs.run_id }}');
          const arts = await github.rest.actions.listWorkflowRunArtifacts({
            owner: context.repo.owner,
            repo: context.repo.repo,
            run_id: run_id,
            per_page: 50
          });
          console.log('Artifacts in fetch-posts run:', arts.data.artifacts.map(a => `${a.name} (${a.size_in_bytes} bytes)`));

    - name: Download DB artifacts from fetch-posts using GitHub CLI
      if: steps.get_run_fetch.outputs.run_id != ''
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        echo "Downloading artifacts from run ${{ steps.get_run_fetch.outputs.run_id }}"
        gh run download ${{ steps.get_run_fetch.outputs.run_id }} --name posts-database --dir data/ || echo "posts-database not found"
        gh run download ${{ steps.get_run_fetch.outputs.run_id }} --name posts-database-latest --dir data/ || echo "posts-database-latest not found"
      continue-on-error: true

    - name: Get latest successful run id (daily-post)
      id: get_run_daily
      if: steps.get_run_fetch.outputs.run_id == ''
      uses: actions/github-script@v7
      with:
        script: |
          const runs = await github.rest.actions.listWorkflowRuns({
            owner: context.repo.owner,
            repo: context.repo.repo,
            workflow_id: 'daily-post.yml',
            branch: 'main',
            per_page: 20,
            status: 'success'
          });
          const run = runs.data.workflow_runs && runs.data.workflow_runs[0];
          core.setOutput('run_id', run ? String(run.id) : '');

    - name: List artifacts for daily-post run
      if: steps.get_run_fetch.outputs.run_id == '' && steps.get_run_daily.outputs.run_id != ''
      uses: actions/github-script@v7
      with:
        script: |
          const run_id = parseInt('${{ steps.get_run_daily.outputs.run_id }}');
          const arts = await github.rest.actions.listWorkflowRunArtifacts({
            owner: context.repo.owner,
            repo: context.repo.repo,
            run_id: run_id,
            per_page: 50
          });
          console.log('Artifacts in daily-post run:', arts.data.artifacts.map(a => `${a.name} (${a.size_in_bytes} bytes)`));

    - name: Download DB artifacts from daily-post using GitHub CLI (fallback)
      if: steps.get_run_fetch.outputs.run_id == '' && steps.get_run_daily.outputs.run_id != ''
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        echo "Downloading artifacts from daily-post run ${{ steps.get_run_daily.outputs.run_id }}"
        gh run download ${{ steps.get_run_daily.outputs.run_id }} --name posts-database --dir data/ || echo "posts-database not found"
        gh run download ${{ steps.get_run_daily.outputs.run_id }} --name posts-database-latest --dir data/ || echo "posts-database-latest not found"
      continue-on-error: true

    - name: Normalize downloaded DB filename
      run: |
        echo "Files in data before normalization:" && ls -lah data || true
        DB_CANDIDATE=$(find data -maxdepth 2 -type f -name "*.db" | head -n1 || true)
        if [ -n "$DB_CANDIDATE" ]; then
          echo "Found DB candidate: $DB_CANDIDATE"
          cp "$DB_CANDIDATE" data/posts.db
        else
          echo "No .db file found in downloaded artifacts"
        fi
        echo "Files in data after normalization:" && ls -lah data || true

    - name: Show database status
      env:
        BLOG_RSS_FEED_URL: ${{ secrets.BLOG_RSS_FEED_URL }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        DATABASE_PATH: ./data/posts.db
        LINKEDIN_ACCESS_TOKEN: ${{ secrets.LINKEDIN_ACCESS_TOKEN }}
        LINKEDIN_USER_ID: ${{ secrets.LINKEDIN_USER_ID }}
        LINKEDIN_ORG_ID: ${{ secrets.LINKEDIN_ORG_ID }}
        LINKEDIN_POST_AS_ORG: ${{ secrets.LINKEDIN_POST_AS_ORG }}
        LINKEDIN_ENABLED: ${{ secrets.LINKEDIN_ENABLED }}
        X_API_KEY: ${{ secrets.X_API_KEY }}
        X_API_SECRET: ${{ secrets.X_API_SECRET }}
        X_ACCESS_TOKEN: ${{ secrets.X_ACCESS_TOKEN }}
        X_ACCESS_TOKEN_SECRET: ${{ secrets.X_ACCESS_TOKEN_SECRET }}
        X_BEARER_TOKEN: ${{ secrets.X_BEARER_TOKEN }}
      run: |
        echo "============================================================"
        echo "DATABASE STATUS REPORT"
        echo "============================================================"
        echo "Timestamp: $(date)"
        echo ""
        
        # Check if database exists
        if [ -f "./data/posts.db" ]; then
          echo "‚úÖ Database file exists: ./data/posts.db"
          echo "üìä Database size: $(du -h ./data/posts.db | cut -f1)"
          echo ""
          
          # Show database contents using Python
          python main.py --status
          echo ""
          
          # Show raw database contents
          echo "üìã Raw Database Contents:"
          echo "------------------------"
          echo "Blog Posts:"
          sqlite3 ./data/posts.db "SELECT id, title, published_date, fetched_at FROM blog_posts ORDER BY published_date DESC LIMIT 10;" || echo "No blog posts found"
          echo ""
          echo "Posted Messages:"
          sqlite3 ./data/posts.db "SELECT id, blog_post_id, message_index, posted_to_linkedin, posted_to_x, posted_at FROM posted_messages ORDER BY id DESC LIMIT 10;" || echo "No posted messages found"
          echo ""
          
          # Show unpublished messages with details
          echo "üìù UNPUBLISHED MESSAGES (Not Posted Yet):"
          echo "=========================================="
          sqlite3 ./data/posts.db "
            SELECT 
              pm.id as msg_id,
              bp.title as blog_title,
              pm.message_index + 1 as msg_num,
              datetime(pm.scheduled_for) as scheduled,
              CASE 
                WHEN pm.posted_to_linkedin = 1 AND pm.posted_to_x = 1 THEN '‚úÖ Both'
                WHEN pm.posted_to_linkedin = 1 THEN 'üîó LinkedIn Only'
                WHEN pm.posted_to_x = 1 THEN 'ùïè X Only'
                ELSE '‚è≥ Pending'
              END as status,
              substr(pm.message_text, 1, 60) || '...' as preview
            FROM posted_messages pm
            JOIN blog_posts bp ON pm.blog_post_id = bp.id
            WHERE pm.posted_at IS NULL OR (pm.posted_to_linkedin = 0 OR pm.posted_to_x = 0)
            ORDER BY pm.scheduled_for ASC
          " -header -column || echo "No unpublished messages found"
          echo ""
          echo "Total unpublished messages:"
          sqlite3 ./data/posts.db "
            SELECT COUNT(*) 
            FROM posted_messages 
            WHERE posted_at IS NULL OR (posted_to_linkedin = 0 OR posted_to_x = 0)
          " || echo "0"
          echo ""
          
          echo "Database Schema:"
          sqlite3 ./data/posts.db ".schema"
        else
          echo "‚ùå Database file does not exist"
          echo "This could mean:"
          echo "  - No workflows have run yet"
          echo "  - No artifacts have been created"
          echo "  - Database hasn't been initialized"
        fi
        
        echo ""
        echo "============================================================"
        echo "END OF DATABASE STATUS REPORT"
        echo "============================================================"
    
    - name: Upload database status as artifact
      if: always() && hashFiles('data/posts.db') != ''
      uses: actions/upload-artifact@v4
      with:
        name: database-status-report
        path: |
          data/posts.db
        retention-days: 7
